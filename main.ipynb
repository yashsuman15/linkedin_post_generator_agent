{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dc8a079",
   "metadata": {},
   "source": [
    "[![Labellerr](https://storage.googleapis.com/labellerr-cdn/%200%20Labellerr%20template/notebook.webp)](https://www.labellerr.com)\n",
    "\n",
    "# **LinkedIn Post Generator Agent**\n",
    "\n",
    "---\n",
    "\n",
    "[![labellerr](https://img.shields.io/badge/Labellerr-BLOG-black.svg)](https://www.labellerr.com/blog/<BLOG_NAME>)\n",
    "[![Youtube](https://img.shields.io/badge/Labellerr-YouTube-b31b1b.svg)](https://www.youtube.com/@Labellerr)\n",
    "[![Github](https://img.shields.io/badge/Labellerr-GitHub-green.svg)](https://github.com/Labellerr/Hands-On-Learning-in-Computer-Vision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c54e2f9",
   "metadata": {},
   "source": [
    "This notebook implements an automated LinkedIn post generator using CrewAI framework. The system uses two specialized agents:\n",
    "1. Content Extractor Agent - Uses Gemini model to extract and summarize blog content\n",
    "2. LinkedIn Post Writer Agent - Uses Gemini model to create engaging LinkedIn posts\n",
    "\n",
    "## Installation\n",
    "First, install the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758d454b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install crewai python-dotenv requests beautifulsoup4\n",
    "# !pip install \"crewai[tools]\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d45bb6",
   "metadata": {},
   "source": [
    "## Project Overview and Dependencies\n",
    "\n",
    "This section defines the core functionality, goals, and prerequisites for the LinkedIn Post Generator agent. The system is built using CrewAI framework and requires specific Python packages and API keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0a1d51d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "======================================================================================\n",
    "LinkedIn Post Creator Agent - CrewAI Cookbook\n",
    "======================================================================================\n",
    "\n",
    "Goal:\n",
    "- Given a blog URL (published by your company), create a LinkedIn post\n",
    "- Uses CrewAI and its tools\n",
    "- Two Agents:\n",
    "  1. Content Extractor Agent: summarizes or extracts key points using \"gemini-2.5-flash\"\n",
    "  2. LinkedIn Post Writer Agent: writes the LinkedIn post using \"gemma-3-27b\"\n",
    "\n",
    "Prerequisites:\n",
    "- Python 3.8+\n",
    "- pip install crewai python-dotenv requests beautifulsoup4\n",
    "- Working API keys for LLMs (Gemini and Gemma/Gemma-equivalent)\n",
    "\n",
    "======================================================================================\n",
    "\"\"\"\n",
    "# ======================================================================================\n",
    "# 1. IMPORTS AND ENVIRONMENT SETUP\n",
    "# ======================================================================================\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from crewai import Agent, Task, Crew, Process, LLM\n",
    "from crewai.tools import tool\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "assert GEMINI_API_KEY is not None, \"Missing GEMINI_API_KEY in .env\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3897ced3",
   "metadata": {},
   "source": [
    "## Content Fetching Function\n",
    "\n",
    "This section implements the core blog content extraction functionality:\n",
    "- Uses `requests` to fetch blog content\n",
    "- Implements `BeautifulSoup` for HTML parsing\n",
    "- Extracts meaningful text while filtering out navigation, sidebars, and scripts\n",
    "- Includes fallback mechanisms for different blog structures\n",
    "- Limits content length to maintain LLM context window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "545401af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Extraction:\n",
      " Data Annotation Platform Comprehensive solution for efficient data labeling. Video Annotation Platform Advanced tools for dynamic video labeling. Text Annotation Platform Powerful tools for accurate text labeling. Annotation Services Professional data labeling by experts. Image Annotation Platform Efficient and scalable image annotation solution. Dicom Annotation Tools Precision tools for medical image annotations. Interactive Demo Explore the platform with an interactive tour. Product Demos Wat\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ======================================================================================\n",
    "# 2. HELPER FUNCTION - FETCH AND CLEAN BLOG TEXT FROM URL\n",
    "# ======================================================================================\n",
    "def fetch_blog_content(url: str) -> str:\n",
    "    \"\"\"\n",
    "    Downloads and cleans up the main text content from a blog URL.\n",
    "    Returns only main readable text (no nav/sidebar/scripts).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        resp = requests.get(url, timeout=15)\n",
    "        resp.raise_for_status()\n",
    "        soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "        # Heuristic: combine visible <p> tags\n",
    "        text = \" \".join([p.get_text(separator=\" \", strip=True) for p in soup.find_all(\"p\")])\n",
    "        # Fallback to whole body if far too short\n",
    "        if len(text) < 200:\n",
    "            text = soup.body.get_text(separator=\" \", strip=True)\n",
    "        return text[:4000]  # limit to keep LLM context manageable\n",
    "    except Exception as e:\n",
    "        return f\"ERROR fetching blog content: {e}\"\n",
    "\n",
    "# For direct preview/testing\n",
    "if __name__ == \"__main__\":\n",
    "    test_url = \"https://www.labellerr.com/blog/product-update-august-2025/\"\n",
    "    print(\"Sample Extraction:\\n\", fetch_blog_content(test_url)[:500])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f375347",
   "metadata": {},
   "source": [
    "## CrewAI Tool Definition\n",
    "\n",
    "This section defines a custom tool for the CrewAI agent:\n",
    "- Wraps the blog content extraction function with `@tool` decorator\n",
    "- Makes the function accessible to the Content Extractor agent\n",
    "- Provides a clear interface for URL content extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e270f8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ======================================================================================\n",
    "# 3. TOOL FOR CREWAI AGENT TO USE CONTENT EXTRACTION\n",
    "# ======================================================================================\n",
    "@tool(\"Blog Content Extractor\")\n",
    "def extract_blog_content(url: str) -> str:\n",
    "    \"Extracts and cleans up readable text from a blog URL for summarization/LLMs.\"\n",
    "    return fetch_blog_content(url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8727eb2d",
   "metadata": {},
   "source": [
    "## LLM Configuration\n",
    "\n",
    "This section configures the Language Models for both agents:\n",
    "1. Content Extractor LLM:\n",
    "   - Uses Gemini 2.0 Flash Lite\n",
    "   - Low temperature (0.1) for consistent, factual summaries\n",
    "\n",
    "2. Post Writer LLM:\n",
    "   - Uses Gemini 2.5 Flash\n",
    "   - Higher temperature (0.2) for creative writing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "94272549",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ======================================================================================\n",
    "# 4. CONFIGURE LLMs FOR CREWAI\n",
    "# ======================================================================================\n",
    "# Extraction LLM:\n",
    "extracting_llm = LLM(\n",
    "    model=\"gemini/gemini-2.0-flash-lite\",\n",
    "    api_key=GEMINI_API_KEY,\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "# Writing LLM:\n",
    "writing_llm = LLM(\n",
    "    model=\"gemini/gemini-2.5-flash\",\n",
    "    api_key=GEMINI_API_KEY,\n",
    "    temperature=0.2  # Higher for more creative copywriting\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bacf9e",
   "metadata": {},
   "source": [
    "## Agent Definitions\n",
    "\n",
    "This section creates two specialized CrewAI agents:\n",
    "\n",
    "1. Content Extractor Agent:\n",
    "   - Role: Summarize and extract key points from blog posts\n",
    "   - Uses custom blog content extraction tool\n",
    "   - Optimized for accurate content understanding\n",
    "\n",
    "2. LinkedIn Post Writer Agent:\n",
    "   - Role: Create engaging social media content\n",
    "   - Focuses on B2B/B2C communication\n",
    "   - Includes engagement optimization and CTAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "26c53e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ======================================================================================\n",
    "# 5. DEFINE AGENTS\n",
    "# ======================================================================================\n",
    "extractor_agent = Agent(\n",
    "    role=\"Content Extractor\",\n",
    "    goal=\"Summarize and extract the main points from the company blog post URL.\",\n",
    "    backstory=\"Specialist in reading web articles and distilling their most important value, tone, and insights.\",\n",
    "    tools=[extract_blog_content],\n",
    "    llm=extracting_llm,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "writer_agent = Agent(\n",
    "    role=\"LinkedIn Post Writer\",\n",
    "    goal=\"Draft a compelling, engaging LinkedIn post based on the extracted blog summary.\",\n",
    "    backstory=\"Expert in business communication and B2B/B2C social media content, knows how to boost engagement, add value statements and CTAs.\",\n",
    "    llm=writing_llm,\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b45849",
   "metadata": {},
   "source": [
    "## Task Definitions\n",
    "\n",
    "This section defines the sequential tasks for the workflow:\n",
    "\n",
    "1. Content Extraction Task:\n",
    "   - Processes the blog URL\n",
    "   - Creates a concise summary\n",
    "   - Maintains key points and message integrity\n",
    "\n",
    "2. LinkedIn Post Writing Task:\n",
    "   - Creates engaging post content (max 180 words)\n",
    "   - Includes emojis and hashtags\n",
    "   - Adds clear call-to-action\n",
    "   - References company and industry trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4c8d6464",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ======================================================================================\n",
    "# 6. DEFINE TASKS\n",
    "# ======================================================================================\n",
    "extract_task = Task(\n",
    "    description=\"Extract and summarize the core idea and key points from the blog URL: {blog_url}. Output a concise but complete summary suitable for use by a professional content writer.\",\n",
    "    expected_output=\"Summary of the blog post's key points, supporting details, and core message.\",\n",
    "    agent=extractor_agent\n",
    ")\n",
    "write_task = Task(\n",
    "    description=\"Write a polished, creative LinkedIn post (max 180 words) based on the provided blog summary. Use a professional yet approachable tone. End with a clear call to action.use emoji for points. Reference the company and relate the post to industry trends if possible. add hashtags relevant to the topic. add given blog link also\",\n",
    "    expected_output=\"Ready-to-use LinkedIn post copy.\",\n",
    "    agent=writer_agent\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedb8027",
   "metadata": {},
   "source": [
    "## Crew Assembly\n",
    "\n",
    "This section creates the CrewAI workflow:\n",
    "- Combines both agents into a coordinated team\n",
    "- Sets up sequential process flow\n",
    "- Enables verbose output for monitoring\n",
    "- Establishes task dependencies and order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e7f3bbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ======================================================================================\n",
    "# 7. CREATE THE CREW\n",
    "# ======================================================================================\n",
    "linkedin_writer_crew = Crew(\n",
    "    agents=[extractor_agent, writer_agent],\n",
    "    tasks=[extract_task, write_task],\n",
    "    process=Process.sequential,\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0853a152",
   "metadata": {},
   "source": [
    "## Execution\n",
    "\n",
    "This section runs the complete workflow:\n",
    "- Sets the target blog URL\n",
    "- Provides progress feedback\n",
    "- Optionally shows extracted content preview\n",
    "- Executes the full agent workflow\n",
    "- Displays the final LinkedIn post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7697186f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Starting LinkedIn Post Creator\n",
      "================================================================================\n",
      "Blog URL: https://www.labellerr.com/blog/product-update-august-2025/\n",
      "\n",
      "\n",
      "================================================================================\n",
      "LINKEDIN POST COPY\n",
      "================================================================================\n",
      "Tired of video annotations drifting off-sync or struggling with complex workflows? ðŸ˜©\n",
      "\n",
      "At Labellerr, we're thrilled to announce our latest release, bringing unparalleled precision and efficiency to video annotation! This update is a game-changer for anyone working with dynamic data, ensuring cleaner training data and faster AI development.\n",
      "\n",
      "Hereâ€™s whatâ€™s new to streamline your projects:\n",
      "âœ¨ **Frame-Accurate Playback:** Say goodbye to sync issues! Annotations now stick exactly where they should.\n",
      "ðŸŽ¬ **Intuitive Keyframe Management:** Create, manage, and review keyframes directly on your timeline for seamless labeling.\n",
      "ðŸš€ **Smarter SAM2 Tracking:** Track *all* selected annotations in a single job, dramatically speeding up your workflow and cutting compute costs.\n",
      "ðŸŽ¯ **Stable Bounding Box Workflows:** Confidently create and apply SAM2 to bounding box labels without interruptions.\n",
      "ðŸ’¡ **Built-in Filters:** Brightness and contrast filters help you see details clearly, especially in challenging datasets.\n",
      "\n",
      "These enhancements make video annotation more accurate, efficient, and user-friendly, empowering your AI projects with provable results. Ready to experience the difference?\n",
      "\n",
      "Learn more and explore the new features: [Insert Blog Link Here]\n",
      "\n",
      "#DataAnnotation #VideoAnnotation #AI #MachineLearning #ComputerVision #Labellerr #DeepLearning #DataQuality #AutonomousVehicles #HealthcareAI\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ======================================================================================\n",
    "# 8. RUN THE WORKFLOW\n",
    "# ======================================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    BLOG_URL = \"https://www.labellerr.com/blog/product-update-august-2025/\"\n",
    "    \n",
    "    \n",
    "    print(f\"\\n{'='*80}\\nStarting LinkedIn Post Creator\\n{'='*80}\")\n",
    "    print(f\"Blog URL: {BLOG_URL}\\n\")\n",
    "\n",
    "    # Optionally preview the extracted text\n",
    "    # blog_text = fetch_blog_content(BLOG_URL)\n",
    "    # print(f\"\\n{'='*80}\\nEXTRACTED BLOG CONTENT (FIRST 1000 CHARACTERS)\\n{'='*80}\")\n",
    "    # print(blog_text[:1000])\n",
    "\n",
    "    # --- full agent workflow ---\n",
    "    result = linkedin_writer_crew.kickoff(inputs={\"blog_url\": BLOG_URL})\n",
    "    print(f\"\\n{'='*80}\\nLINKEDIN POST COPY\\n{'='*80}\\n\")\n",
    "    print(result)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
